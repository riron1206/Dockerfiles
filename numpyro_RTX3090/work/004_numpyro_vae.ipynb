{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpyro で VAE 試す\n",
    "https://zenn.dev/asei/articles/ee0525e452fdb3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/gist/AseiSugiyama/2e0211035bd14ebbbe60fdb3b48e438f/numpyro_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aXDRxifjo9Y8"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade numpyro\n",
    "#!pip install --upgrade jax jaxlib==0.1.56+cuda101 -f https://storage.googleapis.com/jax-releases/jax_releases.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Z6MUOZNsikub"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from jax import jit, lax, random\n",
    "from jax.experimental import stax  # jaxでニューラルネット組むためのモジュール\n",
    "import jax.numpy as jnp\n",
    "from jax.random import PRNGKey\n",
    "\n",
    "import numpyro\n",
    "from numpyro import optim\n",
    "import numpyro.distributions as dist\n",
    "from numpyro.examples.datasets import MNIST, load_dataset\n",
    "from numpyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qr1AgIJbAuT5"
   },
   "outputs": [],
   "source": [
    "# VAEはGPUじゃないとめっちゃ遅い\n",
    "numpyro.set_platform(\"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zYtpjxzKiqfN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/ipykernel_3265/.results'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_DIR = os.path.abspath(os.path.join(os.path.dirname(inspect.getfile(lambda: None)),\n",
    "                              '.results'))\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1BSYjejNisdN"
   },
   "outputs": [],
   "source": [
    "def encoder(hidden_dim, z_dim):\n",
    "    return stax.serial(\n",
    "        stax.Dense(hidden_dim, W_init=stax.randn()), stax.Softplus,\n",
    "        stax.FanOut(2),  # ノード数を hidden_dim -> 2 にしてるってこと？\n",
    "        stax.parallel(stax.Dense(z_dim, W_init=stax.randn()),\n",
    "                      stax.serial(stax.Dense(z_dim, W_init=stax.randn()), stax.Exp)),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "INdM_w5liu_R"
   },
   "outputs": [],
   "source": [
    "def decoder(hidden_dim, out_dim):\n",
    "    return stax.serial(\n",
    "        stax.Dense(hidden_dim, W_init=stax.randn()), stax.Softplus,\n",
    "        stax.Dense(out_dim, W_init=stax.randn()), stax.Sigmoid,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V7SXnrkQixAY"
   },
   "outputs": [],
   "source": [
    "def model(batch, hidden_dim=400, z_dim=100):\n",
    "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
    "    batch_dim, out_dim = jnp.shape(batch)\n",
    "    decode = numpyro.module('decoder', decoder(hidden_dim, out_dim), (batch_dim, z_dim))\n",
    "    z = numpyro.sample('z', dist.Normal(jnp.zeros((z_dim,)), jnp.ones((z_dim,))))  # パラメータ\n",
    "    img_loc = decode(z)\n",
    "    return numpyro.sample('obs', dist.Bernoulli(img_loc), obs=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_s_ZNrpoizkB"
   },
   "outputs": [],
   "source": [
    "def guide(batch, hidden_dim=400, z_dim=100):\n",
    "    batch = jnp.reshape(batch, (batch.shape[0], -1))\n",
    "    batch_dim, out_dim = jnp.shape(batch)\n",
    "    encode = numpyro.module('encoder', encoder(hidden_dim, z_dim), (batch_dim, out_dim))\n",
    "    z_loc, z_std = encode(batch)\n",
    "    z = numpyro.sample('z', dist.Normal(z_loc, z_std))\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8A0G_4Avi1cV"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def binarize(rng_key, batch):\n",
    "    return random.bernoulli(rng_key, batch).astype(batch.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "S9RYrODii35S"
   },
   "outputs": [],
   "source": [
    "hidden_dim = 400\n",
    "z_dim = 50\n",
    "learning_rate = 1.0e-3\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "encoder_nn = encoder(hidden_dim, z_dim)\n",
    "decoder_nn = decoder(hidden_dim, 28 * 28)\n",
    "adam = optim.Adam(learning_rate)\n",
    "svi = SVI(model, guide, adam, Trace_ELBO(), hidden_dim=hidden_dim, z_dim=z_dim)\n",
    "rng_key = PRNGKey(0)\n",
    "train_init, train_fetch = load_dataset(MNIST, batch_size=batch_size, split='train')\n",
    "test_init, test_fetch = load_dataset(MNIST, batch_size=batch_size, split='test')\n",
    "num_train, train_idx = train_init()\n",
    "rng_key, rng_key_binarize, rng_key_init = random.split(rng_key, 3)\n",
    "sample_batch = binarize(rng_key_binarize, train_fetch(0, train_idx)[0])\n",
    "svi_state = svi.init(rng_key_init, sample_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function jax.experimental.stax.serial.<locals>.init_fun(rng, input_shape)>,\n",
       " <function jax.experimental.stax.serial.<locals>.apply_fun(params, inputs, **kwargs)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hoG5Cs7MldrJ"
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def epoch_train(svi_state, rng_key):\n",
    "    def body_fn(i, val):\n",
    "        loss_sum, svi_state = val\n",
    "        rng_key_binarize = random.fold_in(rng_key, i)\n",
    "        batch = binarize(rng_key_binarize, train_fetch(i, train_idx)[0])\n",
    "        svi_state, loss = svi.update(svi_state, batch)\n",
    "        loss_sum += loss\n",
    "        return loss_sum, svi_state\n",
    "\n",
    "    return lax.fori_loop(0, num_train, body_fn, (0., svi_state))\n",
    "\n",
    "@jit\n",
    "def eval_test(svi_state, rng_key):\n",
    "    def body_fun(i, loss_sum):\n",
    "        rng_key_binarize = random.fold_in(rng_key, i)\n",
    "        batch = binarize(rng_key_binarize, test_fetch(i, test_idx)[0])\n",
    "        # FIXME: does this lead to a requirement for an rng_key arg in svi_eval?\n",
    "        loss = svi.evaluate(svi_state, batch) / len(batch)\n",
    "        loss_sum += loss\n",
    "        return loss_sum\n",
    "\n",
    "    loss = lax.fori_loop(0, num_test, body_fun, 0.)\n",
    "    loss = loss / num_test\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RFkmEgRMloxR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: loss = 192.72499084472656 (3.79 s.)\n",
      "Epoch 1: loss = 179.18263244628906 (0.10 s.)\n",
      "Epoch 2: loss = 152.52359008789062 (0.10 s.)\n",
      "Epoch 3: loss = 135.58538818359375 (0.09 s.)\n",
      "Epoch 4: loss = 126.55363464355469 (0.09 s.)\n",
      "Epoch 5: loss = 119.89852905273438 (0.09 s.)\n",
      "Epoch 6: loss = 115.1008529663086 (0.09 s.)\n",
      "Epoch 7: loss = 111.9155502319336 (0.09 s.)\n",
      "Epoch 8: loss = 109.52226257324219 (0.09 s.)\n",
      "Epoch 9: loss = 107.90716552734375 (0.09 s.)\n",
      "Epoch 10: loss = 106.52417755126953 (0.09 s.)\n",
      "Epoch 11: loss = 105.74427032470703 (0.09 s.)\n",
      "Epoch 12: loss = 104.68888092041016 (0.09 s.)\n",
      "Epoch 13: loss = 104.14228820800781 (0.09 s.)\n",
      "Epoch 14: loss = 103.52923583984375 (0.09 s.)\n",
      "Epoch 15: loss = 102.91914367675781 (0.09 s.)\n",
      "Epoch 16: loss = 102.47251892089844 (0.09 s.)\n",
      "Epoch 17: loss = 102.09611511230469 (0.09 s.)\n",
      "Epoch 18: loss = 101.822998046875 (0.09 s.)\n",
      "Epoch 19: loss = 101.4325942993164 (0.09 s.)\n",
      "Epoch 20: loss = 101.27059936523438 (0.09 s.)\n",
      "Epoch 21: loss = 100.95370483398438 (0.09 s.)\n",
      "Epoch 22: loss = 100.64990997314453 (0.09 s.)\n",
      "Epoch 23: loss = 100.39730072021484 (0.09 s.)\n",
      "Epoch 24: loss = 100.37972259521484 (0.09 s.)\n",
      "Epoch 25: loss = 100.46894836425781 (0.09 s.)\n",
      "Epoch 26: loss = 100.26699829101562 (0.09 s.)\n",
      "Epoch 27: loss = 100.01629638671875 (0.09 s.)\n",
      "Epoch 28: loss = 99.62784576416016 (0.09 s.)\n",
      "Epoch 29: loss = 99.72679138183594 (0.09 s.)\n",
      "Epoch 30: loss = 99.71392059326172 (0.10 s.)\n",
      "Epoch 31: loss = 99.39466094970703 (0.09 s.)\n",
      "Epoch 32: loss = 99.45028686523438 (0.09 s.)\n",
      "Epoch 33: loss = 99.26205444335938 (0.09 s.)\n",
      "Epoch 34: loss = 99.11368560791016 (0.09 s.)\n",
      "Epoch 35: loss = 98.95701599121094 (0.09 s.)\n",
      "Epoch 36: loss = 98.755615234375 (0.09 s.)\n",
      "Epoch 37: loss = 98.66336059570312 (0.09 s.)\n",
      "Epoch 38: loss = 98.93140411376953 (0.09 s.)\n",
      "Epoch 39: loss = 98.82658386230469 (0.09 s.)\n",
      "Epoch 40: loss = 98.76329040527344 (0.09 s.)\n",
      "Epoch 41: loss = 98.39715576171875 (0.09 s.)\n",
      "Epoch 42: loss = 98.5784912109375 (0.09 s.)\n",
      "Epoch 43: loss = 98.46322631835938 (0.09 s.)\n",
      "Epoch 44: loss = 98.38858032226562 (0.09 s.)\n",
      "Epoch 45: loss = 98.31222534179688 (0.09 s.)\n",
      "Epoch 46: loss = 98.33226776123047 (0.09 s.)\n",
      "Epoch 47: loss = 98.333740234375 (0.09 s.)\n",
      "Epoch 48: loss = 98.24761962890625 (0.09 s.)\n",
      "Epoch 49: loss = 98.18384552001953 (0.09 s.)\n",
      "Epoch 50: loss = 98.09346771240234 (0.09 s.)\n",
      "Epoch 51: loss = 98.18779754638672 (0.09 s.)\n",
      "Epoch 52: loss = 98.10436248779297 (0.09 s.)\n",
      "Epoch 53: loss = 98.0488510131836 (0.09 s.)\n",
      "Epoch 54: loss = 97.93658447265625 (0.09 s.)\n",
      "Epoch 55: loss = 97.89940643310547 (0.09 s.)\n",
      "Epoch 56: loss = 97.9402084350586 (0.09 s.)\n",
      "Epoch 57: loss = 98.01432800292969 (0.10 s.)\n",
      "Epoch 58: loss = 97.5851058959961 (0.09 s.)\n",
      "Epoch 59: loss = 97.5942153930664 (0.09 s.)\n",
      "Epoch 60: loss = 97.59625244140625 (0.09 s.)\n",
      "Epoch 61: loss = 97.62028503417969 (0.09 s.)\n",
      "Epoch 62: loss = 97.46007537841797 (0.09 s.)\n",
      "Epoch 63: loss = 97.63812255859375 (0.09 s.)\n",
      "Epoch 64: loss = 97.4747085571289 (0.09 s.)\n",
      "Epoch 65: loss = 97.4907455444336 (0.09 s.)\n",
      "Epoch 66: loss = 97.32670593261719 (0.10 s.)\n",
      "Epoch 67: loss = 97.3381576538086 (0.09 s.)\n",
      "Epoch 68: loss = 97.27400970458984 (0.09 s.)\n",
      "Epoch 69: loss = 97.21943664550781 (0.09 s.)\n",
      "Epoch 70: loss = 97.199951171875 (0.09 s.)\n",
      "Epoch 71: loss = 97.29630279541016 (0.09 s.)\n",
      "Epoch 72: loss = 97.17473602294922 (0.09 s.)\n",
      "Epoch 73: loss = 97.18528747558594 (0.09 s.)\n",
      "Epoch 74: loss = 96.9471664428711 (0.09 s.)\n",
      "Epoch 75: loss = 97.08666229248047 (0.09 s.)\n",
      "Epoch 76: loss = 97.13435363769531 (0.09 s.)\n",
      "Epoch 77: loss = 96.99476623535156 (0.09 s.)\n",
      "Epoch 78: loss = 97.01519012451172 (0.09 s.)\n",
      "Epoch 79: loss = 96.99256134033203 (0.09 s.)\n",
      "Epoch 80: loss = 96.81197357177734 (0.09 s.)\n",
      "Epoch 81: loss = 96.92131805419922 (0.09 s.)\n",
      "Epoch 82: loss = 96.77555084228516 (0.09 s.)\n",
      "Epoch 83: loss = 96.75196838378906 (0.09 s.)\n",
      "Epoch 84: loss = 96.60611724853516 (0.09 s.)\n",
      "Epoch 85: loss = 96.74205017089844 (0.09 s.)\n",
      "Epoch 86: loss = 96.73316955566406 (0.09 s.)\n",
      "Epoch 87: loss = 96.64141845703125 (0.09 s.)\n",
      "Epoch 88: loss = 96.58399200439453 (0.09 s.)\n",
      "Epoch 89: loss = 96.54661560058594 (0.09 s.)\n",
      "Epoch 90: loss = 96.56928253173828 (0.09 s.)\n",
      "Epoch 91: loss = 96.72953033447266 (0.09 s.)\n",
      "Epoch 92: loss = 96.70848846435547 (0.09 s.)\n",
      "Epoch 93: loss = 96.74252319335938 (0.09 s.)\n",
      "Epoch 94: loss = 96.58238983154297 (0.09 s.)\n",
      "Epoch 95: loss = 96.60238647460938 (0.09 s.)\n",
      "Epoch 96: loss = 96.37725067138672 (0.09 s.)\n",
      "Epoch 97: loss = 96.70411682128906 (0.09 s.)\n",
      "Epoch 98: loss = 96.48015594482422 (0.09 s.)\n",
      "Epoch 99: loss = 96.43867492675781 (0.09 s.)\n",
      "CPU times: user 13.5 s, sys: 1.96 s, total: 15.5 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def reconstruct_img(epoch, rng_key):\n",
    "    img = test_fetch(0, test_idx)[0][0]\n",
    "    plt.imsave(os.path.join(RESULTS_DIR, 'original_epoch={}.png'.format(epoch)), img, cmap='gray')\n",
    "    rng_key_binarize, rng_key_sample = random.split(rng_key)\n",
    "    test_sample = binarize(rng_key_binarize, img)\n",
    "    params = svi.get_params(svi_state)\n",
    "    z_mean, z_var = encoder_nn[1](params['encoder$params'], test_sample.reshape([1, -1]))\n",
    "    z = dist.Normal(z_mean, z_var).sample(rng_key_sample)\n",
    "    img_loc = decoder_nn[1](params['decoder$params'], z).reshape([28, 28])\n",
    "    plt.imsave(os.path.join(RESULTS_DIR, 'recons_epoch={}.png'.format(epoch)), img_loc, cmap='gray')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    rng_key, rng_key_train, rng_key_test, rng_key_reconstruct = random.split(rng_key, 4)\n",
    "    t_start = time.time()\n",
    "    num_train, train_idx = train_init()\n",
    "    _, svi_state = epoch_train(svi_state, rng_key_train)\n",
    "    rng_key, rng_key_test, rng_key_reconstruct = random.split(rng_key, 3)\n",
    "    num_test, test_idx = test_init()\n",
    "    test_loss = eval_test(svi_state, rng_key_test)\n",
    "    reconstruct_img(i, rng_key_reconstruct)\n",
    "    print(\"Epoch {}: loss = {} ({:.2f} s.)\".format(i, test_loss, time.time() - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZJKEV2ll9so"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPKDuXuOiukiElV+kW/eTNk",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "numpyro_vae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
